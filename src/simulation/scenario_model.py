"""
civic-lens: Monte Carlo scenario simulation engine.

Scenarios S0–S5 defined in docs/SCENARIO_DEFINITIONS.md.
Frozen after Phase B commit — no new scenarios added after freeze.

KEY ASSUMPTIONS (all explicit, all documented):

1. BOROUGH INDEPENDENCE
   Boroughs are simulated independently. No cross-borough swing
   correlation is modelled. Local elections are driven by borough-specific
   dynamics (candidate quality, local issues, incumbency) that make
   national correlation assumptions unjustified at this geography.

3. BOOTSTRAP SOURCE — BOROUGH-SPECIFIC
   Swing distributions are bootstrapped from BOROUGH-SPECIFIC historical
   error distributions derived from the calibration backtest (2018→2022→
   predict 2025). Each borough's uncertainty reflects its own historical
   volatility — not a national pool, not assumed parametric distributions.
   Boroughs with insufficient history (< 2 complete election cycles) fall
   back to the tier-level pooled distribution.

4. SCENARIO OUTPUTS — METRIC DISTRIBUTIONS ONLY
   Scenario simulation produces P10/P50/P90 distributions of volatility
   METRICS only. Seat projections are NOT generated by the simulation.
   Seat Change (ΔS) is computed from realised historical data only.

5. ITERATION COUNT — FROZEN
   2,000 iterations per scenario per borough. Do not increase.
   Calibration logic determines output quality, not simulation volume.
"""

import pandas as pd
import numpy as np
from pathlib import Path

N_ITERATIONS = 2_000  # FROZEN — see scope-lock.md
RNG_SEED = 20260430   # FROZEN — guarantees Monte Carlo determinism; recorded in artifacts/model_lock.txt

SCENARIOS = {
    "S0": "Baseline (0pp uniform swing)",
    "S1": "High volatility continuation (+2pp challenger)",
    "S2": "Partial recovery (+1.5pp established)",
    "S3": "Challenger surge (+4pp challenger)",
    "S4": "Deprivation turnout shift (+3pp ΔT in IMD deciles 1-3)",
    "S5": "Stability reversion (London VI cap — empirical or REMOVED)",
}

# Fallback tier used when borough has < 2 complete election cycles
TIER_FALLBACK = {
    "metro":    "tier1_metro",
    "london":   "tier2_london",
    "yorkshire":"tier3_yorkshire",
}


def load_borough_error_distributions(backtest_path: str) -> dict:
    """
    Load borough-specific error distributions from calibration backtest.

    Returns: {borough: {metric: {"mean": float, "std": float}}}

    For boroughs with insufficient history, falls back to tier-level pool.
    See BOOTSTRAP SOURCE note above.
    """
    # TODO: implement
    raise NotImplementedError


def identify_challenger(df: pd.DataFrame, borough: str) -> str:
    """
    Challenger = party with highest absolute vote share swing gain in 2025.

    Tie-break: higher 2025 absolute vote share.
    Independents: pooled as 'IND'. Treated as challenger if criterion met.
    'No overall control': recorded in Seat Change metric only.

    Returns: party name string
    """
    # TODO: implement
    raise NotImplementedError


def apply_scenario_assumptions(base_vs: pd.Series, scenario_id: str,
                                 challenger: str) -> pd.Series:
    """
    Apply algebraic scenario assumptions to base vote share series.

    NOTE: This does NOT generate seat projections. It adjusts vote share
    distributions for metric computation only.

    Returns: adjusted vote share Series (must sum to ~1.0)
    """
    # TODO: implement
    raise NotImplementedError


def run_scenario_borough(scenario_id: str,
                          borough_df: pd.DataFrame,
                          error_distributions: dict,
                          n_iter: int = N_ITERATIONS,
                          london_vi_cap: float = None) -> pd.DataFrame:
    """
    Run Monte Carlo simulation for one scenario, one borough.

    Bootstrap source: borough-specific error distributions from backtest.
    Falls back to tier-level pool if borough has insufficient history.

    Args:
        scenario_id:         One of S0–S5
        borough_df:          Cleaned results for this borough (all years)
        error_distributions: Output of load_borough_error_distributions()
        n_iter:              Number of iterations (default 2,000 — do not increase)
        london_vi_cap:       Empirical 90th percentile VI (S5 only; None = S5 not applicable)

    Returns:
        DataFrame: columns = metric, p10, p50, p90
        Note: seat_change column is absent — not projected by simulation.
        VOL (Volatility Score) uses frozen formula: VOL = (0.5 × Σ|swing_i|) + (0.5 × ΔFI)
    """
    # TODO: implement
    raise NotImplementedError


def validate_outputs(scenario_outputs: pd.DataFrame,
                      calibration_errors: dict) -> bool:
    """
    Sanity check outputs before freeze.

    Conditions:
    - No P10 > P50
    - No P50 > P90
    - No interval width narrower than calibration RMSE for that metric
    - Seat Change column absent (not a simulation output)

    If validation fails:
      → Reduce to 4 scenarios (drop S3 + S5, highest uncertainty)
      → Log decision in docs/DECISIONS_LOG.md before model lock

    Returns True if all checks pass. Raises ValueError with details if not.
    """
    # TODO: implement
    raise NotImplementedError


def run_all_scenarios(clean_results_path: str,
                       backtest_path: str,
                       london_vi_cap_path: str,
                       output_path: str) -> None:
    """
    Run all scenarios for all boroughs. Write artifacts/scenario_outputs.csv.

    S5 handling:
      - Read london_vi_cap_path
      - If file contains 'S5_REMOVED': skip S5, log in DECISIONS_LOG.md
      - If numeric value: use as empirical cap
    """
    # TODO: implement
    raise NotImplementedError
